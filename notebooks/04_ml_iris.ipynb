{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "137c8283-6003-45c5-8204-b7e0a98683d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"sepal_length\", \"sepal_width\",\n",
    "    \"petal_length\", \"petal_width\",\n",
    "    \"sepal_area\", \"petal_area\", \"petal_ratio\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed83b90e-c99d-4018-8d6b-37375598f083",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_gold = spark.table(\"workspace.iris_gold.df_iris_gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b57e0e5-34ad-4822-9abb-c780e14bb3e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, PCA\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "df_gold = df_gold.select(\n",
    "    *[F.col(c).cast(\"double\").alias(c) for c in feature_cols],\n",
    "    F.col(\"species\")\n",
    ")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features_raw\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features_raw\",\n",
    "    outputCol=\"features_scaled\",\n",
    "    withMean=True,\n",
    "    withStd=True\n",
    ")\n",
    "\n",
    "pca = PCA(\n",
    "    k=2,\n",
    "    inputCol=\"features_scaled\",\n",
    "    outputCol=\"pca_features\"\n",
    ")\n",
    "\n",
    "kmeans = KMeans(\n",
    "    k=3,\n",
    "    seed=42,\n",
    "    featuresCol=\"pca_features\",\n",
    "    predictionCol=\"cluster\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, scaler, pca, kmeans])\n",
    "pca_model = pipeline.fit(df_gold)\n",
    "df_pca = pca_model.transform(df_gold)\n",
    "\n",
    "model = pipeline.fit(df_gold)\n",
    "df_km = model.transform(df_gold)\n",
    "\n",
    "display(df_km.select(\"pca_features\", \"cluster\", \"species\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e68199b2-413e-43a5-8f6b-20d39e539bb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "evaluator = ClusteringEvaluator(\n",
    "    featuresCol=\"pca_features\",\n",
    "    predictionCol=\"cluster\",\n",
    "    metricName=\"silhouette\",\n",
    "    distanceMeasure=\"squaredEuclidean\"\n",
    ")\n",
    "\n",
    "sil = evaluator.evaluate(df_km)\n",
    "print(\"Silhouette:\", sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d6c3512-7385-4818-bdbc-2a0f3da1e6ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pdf = df_km.select(\"pca_features\", \"cluster\", \"species\").toPandas()\n",
    "X = np.vstack(pdf[\"pca_features\"].apply(lambda v: v.toArray()).values)\n",
    "\n",
    "plt.figure()\n",
    "for c in sorted(pdf[\"cluster\"].unique()):\n",
    "    idx = pdf[\"cluster\"] == c\n",
    "    plt.scatter(X[idx, 0], X[idx, 1], label=f\"cluster {c}\")\n",
    "plt.legend()\n",
    "plt.title(\"KMeans sobre PCA (Iris)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_ml_iris",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
